{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from specmf.models import Graph, MultiFidelityModel\n",
    "from specmf.utils import error_analysis, val_test_split\n",
    "from specmf.data import load_data\n",
    "from specmf.plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 14px;\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    \"darcy-flow\", \n",
    "    \"inclusion-field\", \n",
    "    \"inclusion-qoi\",\n",
    "    \"beam\",\n",
    "    \"cavity\",\n",
    "    \"burgers\",\n",
    "]\n",
    "\n",
    "dataset_name = dataset_names[0]\n",
    "\n",
    "x_LF, x_HF = load_data(\n",
    "    dataset_name,\n",
    "    preprocess=True,\n",
    "    normalize=True, \n",
    "    flatten=True,\n",
    "    )\n",
    "\n",
    "print(f\"{x_LF.shape=}\", f\"{x_HF.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(x_LF, x_HF, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-fidelity model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create graph and model instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "graph_config = {\n",
    "    'metric': 'euclidean',\n",
    "    'dist_space': 'ambient',\n",
    "    'n_components': None,\n",
    "    'method': 'full',\n",
    "    'k_nn': None,\n",
    "    'corr_scale': None,\n",
    "    'k_adj': 7,\n",
    "    'p': 0.5,\n",
    "    'q': 0.5,\n",
    "}\n",
    "g_LF = Graph(data=x_LF, **graph_config)\n",
    "\n",
    "# Create the model \n",
    "model_config = {\n",
    "    'sigma': 0.01,\n",
    "    'method': 'full'\n",
    "}\n",
    "model = MultiFidelityModel(**model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_HF = 100\n",
    "inds_train, labels = model.cluster(g_LF, n_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_size_hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Laplacian spectrum\n",
    "eigvals, eigvecs = g_LF.laplacian_eig()\n",
    "plot_spectrum(eigvals, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split high-fidelity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_val, inds_test = val_test_split(\n",
    "    n_data=x_HF.shape[0], \n",
    "    inds_train=inds_train, \n",
    "    split_ratio=0.5,\n",
    ")\n",
    "\n",
    "x_HF_train = x_HF[inds_train, :]\n",
    "x_HF_val = x_HF[inds_val, :]\n",
    "x_HF_test = x_HF[inds_test, :]\n",
    "\n",
    "print(f\"{x_HF_train.shape=}\", f\"{x_HF_val.shape=}\", f\"{x_HF_test.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt import gp_minimize\n",
    "# from skopt.space import Integer, Real\n",
    "# from skopt.utils import use_named_args\n",
    "\n",
    "# dimensions = [\n",
    "#     Integer(name='beta', low=1, high=8,),\n",
    "#     Real(name='kappa', low=1e-8, high=1e3, prior='log-uniform')\n",
    "#     ]\n",
    "\n",
    "# @use_named_args(dimensions=dimensions)\n",
    "# def cost_fn(beta, kappa):\n",
    "#     \"\"\"\n",
    "#     Custom cost function for the optimization.\n",
    "#     \"\"\"\n",
    "\n",
    "#     model.beta = beta\n",
    "#     model.kappa = kappa\n",
    "\n",
    "#     x_MF, _, _ = model.transform(g_LF, x_HF_train, inds_train)\n",
    "#     x_LF = g_LF.nodes\n",
    "#     _, e_MF = error_analysis(\n",
    "#         x_LF[inds_val],\n",
    "#         x_MF[inds_val],\n",
    "#         x_HF_val,\n",
    "#         return_values=True,\n",
    "#         verbose=0,\n",
    "#     )\n",
    "#     return np.mean(e_MF)\n",
    "\n",
    "# res = gp_minimize(\n",
    "#     func=cost_fn,  \n",
    "#     dimensions=dimensions,      \n",
    "#     acq_func=\"EI\",\n",
    "#     n_calls=200,\n",
    "#     n_initial_points=50,  \n",
    "#     random_state=42,\n",
    "#     verbose=1,\n",
    "#     initial_point_generator='lhs',\n",
    "# )\n",
    "\n",
    "# best_config = {\n",
    "#     'beta': res.x[0],\n",
    "#     'kappa': res.x[1],\n",
    "# }\n",
    "\n",
    "# print(f\"\\nBest configuration: \\n\"\n",
    "#       f\"  - beta = {best_config['beta']}, \\n\"\n",
    "#       f\"  - kappa = {best_config['kappa']}, \\n\")\n",
    "# print(f\"  - cost = {res.fun}\")\n",
    "\n",
    "# x = np.array(res.x_iters)[:, 1]\n",
    "# y = np.array(res.x_iters)[:, 0]\n",
    "# c = res.func_vals\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "# ax1 = ax.scatter(x, y, c=c,)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_ylabel(r'$\\beta$')\n",
    "# ax.set_xlabel(r'$\\kappa$')\n",
    "# plt.colorbar(ax1, label='Validation Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(kappa):\n",
    "    \"\"\"\n",
    "    Custom cost function for the optimization.\n",
    "    \"\"\"\n",
    "    # Create the model \n",
    "    model_config = {\n",
    "        'sigma': 0.01,\n",
    "        'method': 'trunc',\n",
    "        'spectrum_cutoff': 1200,\n",
    "    }\n",
    "    model = MultiFidelityModel(**model_config)\n",
    "\n",
    "    model.kappa = kappa\n",
    "\n",
    "    x_MF, _, dPhi = model.transform(g_LF, x_HF_train, inds_train)\n",
    "    x_LF = g_LF.nodes\n",
    "    _, e_MF = error_analysis(\n",
    "        x_LF[inds_val],\n",
    "        x_MF[inds_val],\n",
    "        x_HF_val,\n",
    "        return_values=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "    return np.mean(e_MF), np.mean(dPhi)\n",
    "\n",
    "Kappas = np.logspace(-12, 8, 50)\n",
    "\n",
    "errors = []\n",
    "dPhis = []\n",
    "\n",
    "for kappa in Kappas:\n",
    "    print(f\"Evaluating kappa = {kappa}\")\n",
    "    error, dPhi = cost_fn(kappa=kappa)\n",
    "    errors.append(error)\n",
    "    dPhis.append(dPhi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_sigma = np.argmin(np.abs(np.array(dPhis) - 3 * model_config[\"sigma\"]))\n",
    "kappa_sigma = Kappas[ind_sigma]\n",
    "print(f\"Optimal kappa = {kappa_sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and the first axis\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot the first set of data\n",
    "ax1.plot(Kappas, errors , 'b-')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel(r'$\\kappa$', fontsize=14)\n",
    "ax1.set_ylabel('error', color='b', fontsize=14)\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Create a twin axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the second set of data\n",
    "ax2.plot(Kappas, dPhis, 'r-')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel(r'$\\mathrm{mean}(\\sqrt{C_{ii}})$', color='r', rotation=0, labelpad=50, fontsize=14)\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "ax1.plot([kappa_sigma, kappa_sigma], [3.5, 19.5], 'k--')\n",
    "ax2.grid('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model with optimized hyperprameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    'kappa': kappa_sigma,\n",
    "}\n",
    "\n",
    "model_config.update(best_config)\n",
    "model = MultiFidelityModel(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_MF, C_phi, dPhi = model.transform(g_LF, x_HF_train, inds_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.hist(dPhi, bins=20)\n",
    "ax.set_xlabel(\"Variance\", fontsize=14)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=14)\n",
    "ax.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "ax.tick_params(axis=\"both\", labelsize=12)\n",
    "ax.set_title(\"Variance histogram\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis for validation datadet\n",
    "error_analysis(x_LF[inds_val], x_MF[inds_val], x_HF_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis for unseen test datadet\n",
    "error_analysis(x_LF[inds_test], x_MF[inds_test], x_HF_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis for the whole dataset\n",
    "error_analysis(x_LF, x_MF, x_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_LF = 100 * np.linalg.norm(x_LF - x_HF, axis=1) / (np.mean(np.linalg.norm(x_HF, axis=1)) + 1e-3)\n",
    "E_MF = 100 * np.linalg.norm(x_MF - x_HF, axis=1) / (np.mean(np.linalg.norm(x_HF, axis=1)) + 1e-3)\n",
    "\n",
    "plot_distributions(E_LF, E_MF, bins_LF=50, bins_MF=50, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mf_comparison(x_LF, x_MF, x_HF, dataset_name, dPhi=dPhi, inds_centroids=inds_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generic-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
